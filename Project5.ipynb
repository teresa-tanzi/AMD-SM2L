{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint project AMD + SM2L\n",
    "\n",
    "https://docs.google.com/document/d/1oqoIyRUI_digfIokf53fox0I1eWiTFzQaae-PxMre0Y/edit\n",
    "\n",
    "The task is to implement from scratch a learning algorithm for **regression** with **square loss** (e.g., **ridge regression**). The label to be predicted must be selected among the following 5 attributes, removing the remaining 4 from the dataset:\n",
    "- PERNP (Person's earnings)\n",
    "- PINCP (Person's income)\n",
    "- WAGP (Wages or salary income past 12 months)\n",
    "- HINCP (Household income)\n",
    "- FINCP (Family income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is run inside the Docker container provided in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install PySpark\n",
    "\n",
    "In the docker-compose given in the course, PySpark is already installed, but not in Google Colab. The following cell has to be executed if the notebook is not run in the docker-compose provided by the course, so it has the objective to install Spark on the current machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
    "\n",
    "findspark.init(\"spark-2.4.5-bin-hadoop2.7\")     # SPARK_HOME\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\r\n",
      "      ____              __\r\n",
      "     / __/__  ___ _____/ /__\r\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.5\r\n",
      "      /_/\r\n",
      "                        \r\n",
      "Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_252\r\n",
      "Branch HEAD\r\n",
      "Compiled by user centos on 2020-02-02T19:38:06Z\r\n",
      "Revision cee4ecbb16917fa85f02c635925e2687400aa56b\r\n",
      "Url https://gitbox.apache.org/repos/asf/spark.git\r\n",
      "Type --help for more information.\r\n"
     ]
    }
   ],
   "source": [
    "!pyspark --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The project is based on the analysis of the «2013 American Community Survey» dataset published on Kaggle and released under the public domain license (CC0).\n",
    "\n",
    "https://www.kaggle.com/census/2013-american-community-survey\n",
    "\n",
    "The American Community Survey is an ongoing survey from the US Census Bureau. In this survey, approximately 3.5 million households per year are asked detailed questions about who they are and how they live. Many topics are covered, including ancestry, education, work, transportation, internet use, and residency.\n",
    "\n",
    "There are two types of survey data provided, housing and population:\n",
    "- For the housing data, each row is a housing unit, and the characteristics are properties like rented vs. owned, age of home, etc.\n",
    "- For the population data, each row is a person and the characteristics are properties like age, gender, whether they work, method/length of commute, etc.\n",
    "\n",
    "Each data set is divided in two pieces, \"a\" and \"b\":\n",
    "- \"a\" contains states 1 to 25;\n",
    "- \"b\" contains states 26 to 50.\n",
    "\n",
    "Both data sets have weights associated with them. Weights are included to account for the fact that individuals are not sampled with equal probably (people who have a greater chance of being sampled have a lower weight to reflect this):\n",
    "- Weight variable for the housing data: WGTP\n",
    "- Weight variable for the population data: PWGTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: kaggle 1.5.6\r\n",
      "Uninstalling kaggle-1.5.6:\r\n",
      "  Would remove:\r\n",
      "    /home/jovyan/.local/bin/kaggle\r\n",
      "    /home/jovyan/.local/lib/python3.7/site-packages/kaggle-1.5.6.dist-info/*\r\n",
      "    /home/jovyan/.local/lib/python3.7/site-packages/kaggle/*\r\n",
      "Proceed (y/n)?   Successfully uninstalled kaggle-1.5.6\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"print('y')\" | pip uninstall kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/.cache/pip/wheels/aa/e7/e7/eb3c3d514c33294d77ddd5a856bdd58dc9c1fabbed59a02a2b/kaggle-1.5.6-py3-none-any.whl\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle) (2020.6.20)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.45.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (2.9)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Installing collected packages: kaggle\n",
      "\u001b[33m  WARNING: The script kaggle is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed kaggle-1.5.6\n"
     ]
    }
   ],
   "source": [
    "# install kaggle API for providing the dataset\n",
    "!pip install --user kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kaggle to PATH environment variable\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/home/jovyan/.local/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jovyan/.kaggle’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!echo '{\"username\":\"teresatanzi\",\"key\":\"a64ec0d865925975d3318adf576216b7\"}' >> ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!export KAGGLE_USERNAME=teresatanzi\n",
    "!export KAGGLE_KEY=a64ec0d865925975d3318adf576216b7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download\n",
    "\n",
    "The dataset should not be added to the repository, but downloaded during code execution, for instance via the kaggle API \n",
    "\n",
    "https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2013-american-community-survey.zip to ./data\n",
      "100%|███████████████████████████████████████▉| 916M/916M [02:56<00:00, 5.74MB/s]\n",
      "100%|████████████████████████████████████████| 916M/916M [02:56<00:00, 5.45MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./data\n",
    "!kaggle datasets download census/2013-american-community-survey -p ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"./data/2013-american-community-survey.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./data/2013-american-community-survey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "The task is to implement from scratch a learning algorithm for regression with square loss (e.g., ridge regression). The label to be predicted must be selected among the following 5 attributes, removing the remaining 4 from the dataset:\n",
    "\n",
    "- pusa dataset:\n",
    "    - PERNP (Person's earnings)\n",
    "    - PINCP (Person's income)\n",
    "    - WAGP (Wages or salary income past 12 months)\n",
    "- husa dataset:\n",
    "    - HINCP (Household income)\n",
    "    - FINCP (Family income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "# If we have installed spark according to the first cell of this notebook, run the following command instead\n",
    "#sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "baseDir = os.path.join('./data/2013-american-community-survey')\n",
    "#inputPathA = os.path.join('ss13pusa.csv')\n",
    "#inputPathB = os.path.join('ss13pusb.csv')\n",
    "inputPathA = os.path.join('ss13husa.csv')\n",
    "inputPathB = os.path.join('ss13husb.csv')\n",
    "fileNameA = os.path.join(baseDir, inputPathA)\n",
    "fileNameB = os.path.join(baseDir, inputPathB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe\n",
    "\n",
    "http://spark.apache.org/docs/latest/sql-programming-guide.html: <br>\n",
    "\n",
    "Dataset is a new interface added in Spark 1.6 that provides the benefits of RDDs (strong typing, ability to use powerful lambda functions) with the benefits of Spark SQL’s optimized execution engine. A Dataset can be constructed from JVM objects and then manipulated using functional transformations (map, flatMap, filter, etc.).<br>\n",
    "A DataFrame is a Dataset organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 231\n",
      "Number of rows: 1476313\n"
     ]
    }
   ],
   "source": [
    "dfA = sqlContext.read.csv(fileNameA, header = True)\n",
    "dfB = sqlContext.read.csv(fileNameB, header = True)\n",
    "\n",
    "df = dfA.union(dfB)\n",
    "n = df.count()\n",
    "headerList = df.columns\n",
    "\n",
    "print(\"Number of columns: {}\\nNumber of rows: {}\".format(len(headerList), n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We should trasform data in objects belonging to the class LabeledPoint, but first we have to solve some issues:\n",
    "\n",
    "- we have to deal with missing values: we can substitute those with mean or median of the corresponding column; <br>\n",
    "https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4\n",
    "- we have to deal with categorical values: it should be fine to just discard the feature, because only the first feature is categorical and it has a constant value for all the entry;\n",
    "- we have to deal with missing values in the labels: we could discard data points with no label, because they don't really help in the training process.\n",
    "\n",
    "We should also apply a feature scaling in order to standardize all the values in the interval [0,1] <br>\n",
    "https://www.quora.com/Do-I-need-to-do-feature-scaling-for-simple-linear-regression <br>\n",
    "If you're using the analytical solution, feature scaling wont be of much use. In fact, you may want to refrain from feature scaling so that the model is more comprehensive. However, if you are using the gradient descent algorithm, feature scaling will help the solution converge in a shorter period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/python-data-preprocessing-using-pandas-dataframe-spark-dataframe-and-koalas-dataframe-e44c42258a8f\n",
    "\n",
    "Features engineering can be fundamental to the application of machine learning and it is achieved by various types of data transformation. A feature is a data column in DataFrame. The scope of features engineering varies, but typically includes the following:\n",
    "\n",
    "- Select a subset of existing data columns that are correlated with the prediction target in machine learning (i.e., labels in supervised machine learning)\n",
    "- Create new columns based on existing columns (i.e., create derived features)\n",
    "- Scale column values into a certain range (i.e., scaling column values into the range of [0,1] or [-1,1] in deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/60281354/apply-minmaxscaler-on-multiple-columns-in-pyspark\n",
    "# lentissima\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def scale_features(df):\n",
    "    \"\"\"Scales all the features of a PySpark DataFrame so that all the values belongs to a range of [0, 1].\n",
    "\n",
    "    Args:\n",
    "        df (PySpark DataFrame): DataFrame we want to normalize.\n",
    "\n",
    "    Returns:\n",
    "        PySpark DataFrame: DataFrame with all the feature normalized in the interval [0, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    # scale all the columns in the dataframe\n",
    "    columns_to_scale = df.columns\n",
    "    \n",
    "    # MinMaxScaler works on vectors\n",
    "    assemblers = [VectorAssembler(inputCols = [col], outputCol = col + \"_vec\") for col in columns_to_scale]\n",
    "    scalers = [MinMaxScaler(inputCol = col + \"_vec\", outputCol = col + \"_scaled\") for col in columns_to_scale]\n",
    "    \n",
    "    # Pipeline of VectorAssembler and MinMaxScaler\n",
    "    pipeline = Pipeline(stages = assemblers + scalers)\n",
    "    \n",
    "    # fitting pipeline on dataframe\n",
    "    df = pipeline.fit(df).transform(df)\n",
    "    \n",
    "    # UDF for converting column type from vector to double type\n",
    "    # otherwise it return a vector for each new value we are adding\n",
    "    unlist = udf(lambda x: float(list(x)[0]), DoubleType())\n",
    "    \n",
    "    # names of the normalized columns\n",
    "    names = {x + \"_scaled\": x for x in columns_to_scale}\n",
    "\n",
    "    # convert vectors to double and restore original columns names\n",
    "    df = df.select([unlist(col(c)).alias(names[c]) for c in names.keys()])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We reduced the number of attributes from 231 to 215.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "def preprocess (df, na_threshold, label, imputer_strategy, feature_scaling = True):\n",
    "    \"\"\"Preprocess a PySpark DataFrame, dealing with null values.\n",
    "\n",
    "    Args:\n",
    "        df (PySpark DataFrame): DataFrame read by the csv file.\n",
    "        na_threshold (float between 0 and 1): threshold that establish if a feature should be dropped or not\n",
    "            based on its percentage of null values.\n",
    "        label (string): feature that corresponds to the chosen label to be predicted.\n",
    "        imputer_strategy (string): it can be `mean` or `median`, based on the imputation strategy we choose.\n",
    "        feature_scaling (boolean): if True, all the feature in the DataFrame are scaled to have values belonging\n",
    "            in intervall [0, 1], but it slows the process.\n",
    "\n",
    "    Returns:\n",
    "        PySpark DataFrame: Restult of the processing of the original DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove RT: it is categorical and it has a constant value for all the data points in the dataset\n",
    "    df = df.drop('RT')\n",
    "    \n",
    "    # remove all the features that correspond to possible labels, but are not the chosen one\n",
    "    possible_labels = ['PERNP', 'PINCP', 'WAGP'] if inputPathA == 'ss13pusa.csv' else ['HINCP', 'FINCP']        \n",
    "    possible_labels.remove(label)\n",
    "    \n",
    "    for i in possible_labels:\n",
    "        df = df.drop(i)\n",
    "    \n",
    "    # cast features into double\n",
    "    df = df.select([col(c).cast(\"double\") for c in df.columns])\n",
    "    #df = df.select([col(c).cast(\"integer\") for c in df.columns])\n",
    "        \n",
    "    # compute the dataframe containing, for each of the features, the percentange of null values\n",
    "    null_df = df.select([(count(when(col(c).isNull(), c))/n).alias(c) for c in df.columns])\n",
    "    \n",
    "    # remove form the original dataframe all the attributes that have more null values than a given threshold\n",
    "    scheme = df.columns\n",
    "    null_distr = null_df.take(1)[0].asDict().values()\n",
    "    \n",
    "    for i in np.where(np.array(list(null_distr)) > na_threshold)[0]:\n",
    "        df = df.drop(scheme[i])\n",
    "        \n",
    "    print('We reduced the number of attributes from {} to {}.'.format(len(headerList), len(df.columns)))\n",
    "    \n",
    "    # remove all the data points with null value for the label\n",
    "    df = df.filter(df[label].isNotNull())    \n",
    "    \n",
    "    # replace all the missing values with the mean value of the corresponding feature\n",
    "    imputer = Imputer()\n",
    "    imputer.setInputCols(df.columns)\n",
    "    imputer.setOutputCols(df.columns)\n",
    "    imputer.setStrategy(imputer_strategy)\n",
    "\n",
    "    df = imputer.fit(df).transform(df)\n",
    "    \n",
    "    # scale the features (forse da fare prima dell'imputer)\n",
    "    if feature_scaling: df = scale_features(df)\n",
    "\n",
    "    return df\n",
    "        \n",
    "na_threshold = .6\n",
    "label = 'HINCP'\n",
    "imputer_strategy = 'mean'\n",
    "\n",
    "df = preprocess(df, na_threshold, label, imputer_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is almost done. We may want to:\n",
    "\n",
    "- Remove column SERIALNO (it is just a unique number for every observation);\n",
    "- Tune the threshold for the feature dropping based on the percentage of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we save out DataFrame as a `.csv` file in order to avoid the preprocessing operation in the future runs of the project. Instead, we will directly read de preprocessed file as a PySpark Dataframe and we will directly execute the regressor on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "baseDir = os.path.join('./data')\n",
    "inputPath = os.path.join('preprocessed_data')\n",
    "fileName = os.path.join(baseDir, inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write\n",
    "df.write.csv(fileName, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 215\n",
      "Number of rows: 1211264\n"
     ]
    }
   ],
   "source": [
    "# read\n",
    "df = sqlContext.read.csv(fileName, header = True)\n",
    "n = df.count()\n",
    "headerList = df.columns\n",
    "\n",
    "print(\"Number of columns: {}\\nNumber of rows: {}\".format(len(headerList), n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled points\n",
    "\n",
    "Let us now cast all the data point into `LabeledPoint`. The label is the one we select from the 5 different possible labels given by the project, while all the other possible labels have to be removed from the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0,0.15379668698809854,0.625,0.014244811327473968,0.6666666666666666,0.8363636363636363,0.5,0.5,0.053610503282275714,0.05263157894736842,0.5,0.0,0.0,0.0,0.15789473684210525,0.1111111111111111,1.0,1.0,1.0,1.0,1.0,0.3823038397328882,1.0,1.0,0.00013890818169190166,0.0036429872495446266,1.0,0.25,0.0,0.0,0.0,1.0,1.0,0.0,0.20833333333333334,0.0,0.5,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0355818970030786,0.16666666666666666,0.007251812953238309,0.5625,0.42857142857142855,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.0,1.0,0.5,1.0,0.02356361410756637,0.0,0.0,1.0,0.2835820895522388,0.0,0.5714285714285714,0.5714285714285714,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.09981785063752277,0.07490144546649145,0.08244680851063829,0.07751147373788883,0.19058713886300094,0.20123456790123456,0.22226111305565277,0.04375752709755119,0.030775899436497615,0.09764758100310697,0.05496378355347252,0.05475206611570248,0.055145462440295265,0.046493301812450746,0.11082138200782268,0.017317760773258157,0.14175152749490835,0.08549874266554904,0.07006071929005138,0.0602540834845735,0.08378136200716846,0.10647279549718575,0.14802211824755424,0.10853658536585366,0.06501128668171557,0.1028914757791964,0.06501182033096926,0.046903460837887066,0.06318560772268539,0.061252268602540835,0.15053367684946634,0.09739747634069401,0.09456148946594807,0.10628875110717449,0.07326355851569934,0.05792163543441227,0.025423728813559324,0.13582531458179126,0.09357277882797732,0.1397459165154265,0.10826844642195031,0.08057090239410682,0.06535648994515539,0.07094594594594594,0.09738012852199704,0.2765838682668155,0.22750997850782928,0.13693940431359122,0.06636363636363636,0.08935546875,0.0544799639801891,0.08288530465949821,0.09509844993715962,0.12261806130903065,0.18197879858657243,0.012830482115085537,0.061953931691818905,0.04268032437046521,0.07045561296383279,0.0440771349862259,0.06515216459494214,0.0780977312390925,0.05337646583097452,0.13026140894993354,0.04462809917355372,0.10110224249334854,0.06839276990718124,0.024171888988361683,0.052452830188679245,0.04214402618657938,0.0816593886462882,0.18639262934089298,0.08300044385264092,0.13405362144857944,0.06258148631029987,0.04665226781857451,0.017051153460381142,0.017437722419928827,0.07174231332357248,0.12639405204460966], 0.0294676670916735\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def parsePoint(row, intercept = True):\n",
    "    \"\"\"Converts a row of a pyspark dataframe into a `LabeledPoint`.\n",
    "\n",
    "    Args:\n",
    "        row: Row of a dataframe composed all of double values. One of those values corresponds to the label, while\n",
    "            other possible lables have to be removed.\n",
    "        intercept (boolean): If True, a feature with a constant value 1 is added in order to learn also\n",
    "            the value of the intercept.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The line is converted into a `LabeledPoint`, which consists of a label and\n",
    "            features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # select chosen label\n",
    "    label = 'HINCP'\n",
    "    \n",
    "    # cast row into a dictionary\n",
    "    row_dict = row.asDict()\n",
    "    label_value = row_dict[label]\n",
    "    \n",
    "    del row_dict[label]\n",
    "    feature_list = list(row_dict.values())\n",
    "    if intercept: feature_list.insert(0, 1)\n",
    "    \n",
    "    return LabeledPoint(label_value, feature_list)\n",
    "\n",
    "# cast DataFrame to RDD (python does not support Spark Dataset API)\n",
    "parsedData = df.rdd.map(lambda s: parsePoint(s))\n",
    "\n",
    "parsedExamplePoint = parsedData.take(1)\n",
    "examplePointFeatures = parsedExamplePoint[0].features\n",
    "examplePointLabel = parsedExamplePoint[0].label\n",
    "print('{}, {}'.format(examplePointFeatures, examplePointLabel))\n",
    "\n",
    "d = len(examplePointFeatures)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning algorithm\n",
    "\n",
    "### Training, validation and test sets\n",
    "\n",
    "https://unraveldata.com/to-cache-or-not-to-cache/\n",
    "\n",
    "Caching RDDs in Spark: It is one mechanism to speed up applications that access the same RDD multiple times. An RDD that is not cached, nor checkpointed, is re-evaluated again each time an action is invoked on that RDD.<br>\n",
    "When to use caching: As suggested in this post, it is recommended to use caching in the following situations: RDD re-use in iterative machine learning applications.<br>\n",
    "\n",
    "Let us sample our dataset in order to test the algorithm. We will use the whole dataset only at the end, to actually train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11901"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lento\n",
    "\n",
    "sampledData = parsedData.sample(False, .01)\n",
    "sampledData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[10487] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "\n",
    "parsedTrainData, parsedValData, parsedTestData = parsedData.randomSplit(weights, seed = seed)\n",
    "#parsedTrainData, parsedValData, parsedTestData = sampledData.randomSplit(weights, seed = seed)\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "parsedTestData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Loss\n",
    "\n",
    "\\begin{equation}\n",
    "    l(\\underline{w}) = \\sum_{j=1}^n (\\hat{y}^{(j)} - y^{(j)})^2\n",
    "\\end{equation}\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\underline{w}$ is the weight vector;\n",
    "- $\\hat{y}^{(j)} = \\underline{w} \\cdot \\underline{x}^{(j)}$ is our prediction with respect to the $j$-th observation;\n",
    "- $y^{(j)}$ is the actual label of the $j$-th observation.\n",
    "\n",
    "\\begin{equation}\n",
    "    l(\\underline{w}) = \\sum_{j=1}^n (\\underline{w} \\cdot \\underline{x}^{(j)} - y^{(j)})^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squaredError(label, prediction):\n",
    "    \"\"\"Calculates the the squared error for a single prediction.\n",
    "\n",
    "    Args:\n",
    "        label (float): The correct value for this observation.\n",
    "        prediction (float): The predicted value for this observation.\n",
    "\n",
    "    Returns:\n",
    "        float: The difference between the `label` and `prediction` squared.\n",
    "    \"\"\"\n",
    "    \n",
    "    return (label - prediction) ** 2\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    \"\"\"Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.\n",
    "\n",
    "    Args:\n",
    "        labelsAndPred (RDD of (float, float)): An `RDD` consisting of (label, prediction) tuples.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the mean of the squared errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sqrt(labelsAndPreds.map(lambda p: squaredError(*p)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression\n",
    "\n",
    "Learn the best weight vector $\\underline{w}^{*}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\underline{w}^{*} = \\operatorname*{argmin}_{\\underline{w}} ||X \\cdot \\underline{w} - \\underline{y}||^2 + \\lambda ||\\underline{w}||^2\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "- $X$ is a matrix where each row is a data point;\n",
    "- $\\underline{y}$ is the vector of the labels;\n",
    "- $\\lambda > 0$ is the regularization parameter (it has to be chosen before hands).\n",
    "\n",
    "We can find the optimal value $\\underline{w}^{*}$ computing the gradient of the function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\underline{w}^{*} = (X^T X + \\lambda I)^{-1} X^T \\underline{y}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient descent\n",
    "\n",
    "If the number $d$ of features and the number $n$ of data points in our dataset are too big, the complexity in time and space of our algorithm may be too high and we may not be able to compute the optimal value for $\\underline{w}$. To solve this problem, we can rely on the gradient descent procedure:\n",
    "\n",
    "1. choose $\\underline{w}_0 \\in R^d$\n",
    "2. $i = 0$\n",
    "3. while (!stop) {\n",
    "    1. $\\underline{w}_{i+1} = \\underline{w}_i - \\xi_i \\left[ \\sum_{j=1}^n (\\underline{w}_i \\cdot \\underline{x}^{(j)} - y^{(j)}) \\underline{x}^{(j)} + \\lambda \\underline{w}_i \\right]$\n",
    "    2. i++\n",
    "4. }\n",
    "5. return $\\underline{w}_i$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\underline{w_i}$ is the approximated optimal weight vector;\n",
    "- stop is a termination criterion of our choice;\n",
    "- $\\xi_i$ is the learning rate:\n",
    "    \\begin{equation}\n",
    "        \\xi_i = \\frac{\\xi_0}{n \\sqrt{i}}\n",
    "    \\end{equation}\n",
    "    \n",
    "#### TODO: non sto considerando l'intercetta $\\underline{w_o}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us focus on the update:\n",
    "\\begin{equation}\n",
    "    \\underline{w}_{i+1} = \\underline{w}_i - \\xi_i \\left[ \\sum_{j=1}^n (\\underline{w}_i \\cdot \\underline{x}^{(j)} - y^{(j)}) \\underline{x}^{(j)} + \\lambda \\underline{w}_i \\right]\n",
    "\\end{equation}\n",
    "\n",
    "Let us begin writing a function that computes the summand of the update: $(\\underline{w}_i \\cdot \\underline{x}^{(j)} - y^{(j)}) \\underline{x}^{(j)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector\n",
    "\n",
    "def gradientSummand(weights, lp):\n",
    "    \"\"\"Calculates the gradient summand for a given weight and `LabeledPoint`.\n",
    "\n",
    "    Note:\n",
    "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
    "        within this function.  For example, they both implement the `dot` method.\n",
    "\n",
    "    Args:\n",
    "        weights (DenseVector): An array of model weights (betas).\n",
    "        lp (LabeledPoint): The `LabeledPoint` for a single observation.\n",
    "\n",
    "    Returns:\n",
    "        DenseVector: An array of values the same length as `weights`.  The gradient summand.\n",
    "    \"\"\"\n",
    "    \n",
    "    return (weights.dot(DenseVector(lp.features)) - lp.label) * lp.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write the function that makes the prediction, based on the weights vector $\\underline{w}$ and the observation $\\underline{x}^{(j)}$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{y}^{(j)} = \\underline{w} \\cdot \\underline{x}^{(j)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabeledPrediction(weights, observation):\n",
    "    \"\"\"Calculates predictions and returns a (label, prediction) tuple.\n",
    "\n",
    "    Note:\n",
    "        The labels should remain unchanged as we'll use this information to calculate prediction\n",
    "        error later.\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): An array with one weight for each features in `trainData`.\n",
    "        observation (LabeledPoint): A `LabeledPoint` that contain the correct label and the\n",
    "            features for the data point.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A (label, prediction) tuple.\n",
    "    \"\"\"\n",
    "    \n",
    "    return (observation.label, weights.dot(DenseVector(observation.features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can write the code that learns the best weight vector $\\underline{w}^*$ using the gradient descent procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "\n",
    "# this is just to print time values in a more human readable form\n",
    "def to_hhmmss(seconds):\n",
    "    times = list(map(int,\n",
    "                     str(datetime.timedelta(seconds=math.floor(seconds))).split(':')))\n",
    "    units = ('hour', 'minute', 'second')\n",
    "    plurals = ['s' if int(t) else '' for t in times]\n",
    "\n",
    "    return ' '.join(['{} {}{}'.format(t, u, p)\n",
    "                    for t, u, p in zip(times, units, plurals) if t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def ridgeRegression(trainData, nIters, csi, regFactor):\n",
    "    \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n",
    "\n",
    "    Note:\n",
    "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
    "        within this function.  For example, they both implement the `dot` method.\n",
    "\n",
    "    Args:\n",
    "        trainData (RDD of LabeledPoint): The labeled data for use in training the model.\n",
    "        nIters (int): The number of iterations of gradient descent to perform.\n",
    "        regFactor (float greater then 0): Regularization factor used in ridge regression.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): A tuple of (weights, training errors).  Weights will be the\n",
    "            final weights (one weight per feature) for the model, and training errors will contain\n",
    "            an error (RMSE) for each iteration of the algorithm.\n",
    "    \"\"\" \n",
    "    \n",
    "    # start the timer\n",
    "    #time_start = time.time()\n",
    "    \n",
    "    # number of data points in training set\n",
    "    # TODO: count è lenta (non è però nel loop, non è questo che rallenta)\n",
    "    n = trainData.count()\n",
    "    \n",
    "    # number of dimensions\n",
    "    d = len(trainData.take(1)[0].features)\n",
    "    \n",
    "    # initialize weight vector with a vector of d zero components\n",
    "    w = np.zeros(d)\n",
    "    \n",
    "    # we will compute and store the training error after each iteration in order to evaluate the process\n",
    "    errorTrain = np.zeros(nIters)\n",
    "    \n",
    "    # setup the progress bar\n",
    "    bar = progressbar.ProgressBar(maxval = nIters,\n",
    "                                  widgets = [progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    for i in range(nIters):\n",
    "        # make the prediction with the current learnt weight vector\n",
    "        labelsAndPredsTrain = trainData.map(lambda p: getLabeledPrediction(w, p))\n",
    "        \n",
    "        # compute the error and add it to the list\n",
    "        errorTrain[i] = calcRMSE(labelsAndPredsTrain)\n",
    "        \n",
    "        # compute the gradient\n",
    "        #gradient = sum([DenseVector(gradientSummand(w, lp)) for lp in trainData.collect()]) + (regFactor * w)\n",
    "        gradientSum = trainData.map(lambda lp: DenseVector(gradientSummand(w, lp))) \\\n",
    "                        .reduce(lambda x, y: x + y)\n",
    "        gradient = gradientSum + (regFactor * w)\n",
    "\n",
    "        # update the learning rate\n",
    "        csi_i = csi / (n * np.sqrt(i + 1))\n",
    "        \n",
    "        # update the weights\n",
    "        w -= csi_i * gradient\n",
    "        #w = (1 - csi_i * regFactoractor) * w - csi_i * gradientSum\n",
    "        \n",
    "        # update the progress bar\n",
    "        bar.update(i + 1)\n",
    "        \n",
    "    bar.finish()\n",
    "    #elapsed = to_hhmmss(time.time()-time_start)\n",
    "    #print('Ridge regression training with parameters:\\n\\tnumber of iterations = {},\\n\\tlearning rate = {},\\\n",
    "    #    \\n\\tregularization factor = {},\\ndone! Time elapsed: {}\\n\\n'.format(numIters, csi, regFactor, elapsed))\n",
    "\n",
    "    return w, errorTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can train our ridge regressor on the trainig data we have and evaluate it on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\r"
     ]
    }
   ],
   "source": [
    "numIters = 1500\n",
    "regFactor = 0\n",
    "csi = 0.01\n",
    "\n",
    "weights, errorTrain = ridgeRegression(parsedTrainData, numIters, csi, regFactor)\n",
    "\n",
    "labelsAndPreds = parsedValData.map(lambda p: getLabeledPrediction(weights, p))\n",
    "rmseVal = calcRMSE(labelsAndPreds)\n",
    "\n",
    "print('Validation RMSE: = {}'.format(rmseVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.038188996904875885, 0.03574522946631133)\n",
      "(0.025012205121885324, 0.0366856103843844)\n",
      "(0.021220322594406024, 0.044566440563499524)\n",
      "(0.01605388265071548, 0.032241761113527716)\n",
      "(0.01994056224138176, 0.04133671285668792)\n",
      "(0.02216829322627585, 0.05006088335436125)\n",
      "(0.030700028913104273, 0.03206874007520002)\n",
      "(0.04254966181147708, 0.04033811051951426)\n",
      "(0.01562729586637406, 0.040543913186189294)\n",
      "(0.02254748147902378, 0.041849295444381866)\n",
      "(0.017333643003739744, 0.03584588793821645)\n",
      "(0.04254966181147708, 0.046343137425555576)\n",
      "(0.037809808652127956, 0.03899966166099329)\n",
      "(0.014679325234504235, 0.03661795155854596)\n",
      "(0.04871147091863094, 0.04865479870486657)\n",
      "(0.03463410703536404, 0.044811251647203586)\n",
      "(0.011740616275707778, 0.03586214531142494)\n",
      "(0.037809808652127956, 0.05046292993224652)\n",
      "(0.011740616275707778, 0.03234720130276035)\n",
      "(0.01411054285538234, 0.03851548839639156)\n"
     ]
    }
   ],
   "source": [
    "out = 20\n",
    "\n",
    "for i in range(out):\n",
    "    print(getLabeledPrediction(weights, parsedTrainData.take(out)[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (12, 7))\n",
    "plt.plot(np.arange(1, len(errorTrain) + 1), errorTrain)\n",
    "fig.suptitle('Evolution of training error through iterations', fontsize=20)\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "plt.ylabel('Training error', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
